{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "G8MgZRsh-nx7",
        "2Ek4byqT-v_9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 📦 Packages and Basic Setup\n",
        "---"
      ],
      "metadata": {
        "id": "Mz5Bvxsh-a7Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qI2ek8K-VBo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U rich flax\n",
        "!pip install --upgrade git+https://github.com/n2cholas/jax-resnet.git\n",
        "\n",
        "import os\n",
        "import jax\n",
        "import random\n",
        "import numpy as np\n",
        "from rich import print\n",
        "\n",
        "import flax.linen as nn\n",
        "import jax.numpy as jnp\n",
        "from jax_resnet import pretrained_resnet, common\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "\n",
        "from typing import Callable, Tuple, Any, List\n",
        "\n",
        "# Experimental options\n",
        "options = tf.data.Options()\n",
        "options.experimental_optimization.noop_elimination = True\n",
        "options.experimental_optimization.apply_default_optimizations = True\n",
        "options.experimental_deterministic = False\n",
        "options.threading.max_intra_op_parallelism = 1\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ⚙ Configuration\n",
        "GLOBAL_SEED = 42  # @param {type: \"number\"}\n",
        "NUM_VIEWS = 2  # @param {type: \"number\"}\n",
        "NUM_TRAINING_EPOCHS = 10  # @param {type: \"number\"}\n",
        "NUM_EVAL_EPOCHS = 100  # @param {type: \"number\"}\n",
        "TRAIN_BATCH_SIZE = 32  # @param {type: \"number\"}\n",
        "EVAL_BATCH_SIZE = 256  # @param {type: \"number\"}\n",
        "MLP_UNITS = 8192  # @param {type: \"number\"}\n",
        "INVAR_COEFF = 25.0  # @param {type: \"number\"}\n",
        "VAR_COEFF = 25.0  # @param {type: \"number\"}\n",
        "COV_COEFF = 1.0  # @param {type: \"number\"}\n",
        "DECAY_STEPS = 1000  # @param {type: \"number\"}\n",
        "WEIGHT_DECAY = 1e-6  # @param {type: \"number\"}\n",
        "BASE_LR = 0.2  # @param {type: \"number\"}\n",
        "EVAL_LR = 0.02  # @param {type: \"number\"}\n",
        "\n",
        "\n",
        "# ============ Random Seed ============\n",
        "def seed_everything(seed=GLOBAL_SEED):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.experimental.numpy.random.seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
        "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"1\"\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"Random seed set as {seed}\")\n",
        "\n",
        "\n",
        "seed_everything()"
      ],
      "metadata": {
        "id": "xS39ofZf-kHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Accelerator Configuration"
      ],
      "metadata": {
        "id": "1yNzs34p_7bB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reference: https://www.kaggle.com/code/odins0n/jax-flax-tf-data-vision-transformers-tutorial\n",
        "\n",
        "if 'TPU_NAME' in os.environ:\n",
        "    import requests\n",
        "    if 'TPU_DRIVER_MODE' not in globals():\n",
        "        url = 'http:' + os.environ['TPU_NAME'].split(':')[1] + ':8475/requestversion/tpu_driver_nightly'\n",
        "        resp = requests.post(url)\n",
        "        TPU_DRIVER_MODE = 1\n",
        "    from jax.config import config as jax_config\n",
        "    jax_config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "    jax_config.FLAGS.jax_backend_target = os.environ['TPU_NAME']\n",
        "    print(\"TPU DETECTED!\")\n",
        "    print('Registered TPU:', jax_config.FLAGS.jax_backend_target)\n",
        "elif \"COLAB_TPU_ADDR\" in os.environ:\n",
        "    import jax.tools.colab_tpu\n",
        "    jax.tools.colab_tpu.setup_tpu()\n",
        "else:\n",
        "    print('No TPU detected.')\n",
        "\n",
        "DEVICE_COUNT = len(jax.local_devices())\n",
        "TPU = DEVICE_COUNT==8\n",
        "\n",
        "if TPU:\n",
        "    print(\"8 cores of TPU ( Local devices in Jax ):\")\n",
        "    print('\\n'.join(map(str,jax.local_devices())))"
      ],
      "metadata": {
        "id": "Hnttj8xM_9YS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🆘 Utility Classes and Functions\n",
        "---"
      ],
      "metadata": {
        "id": "G8MgZRsh-nx7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🖖 Utilites for Data Augmentation\n"
      ],
      "metadata": {
        "id": "TqWjzdgR-pDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GAUSSIAN_P = [1.0, 0.1]\n",
        "SOLARIZE_P = [0.0, 0.2]\n",
        "\n",
        "def shuffle_zipped_output(a: Any, b: Any) -> Tuple[Any]:\n",
        "    \"\"\"Shuffle the given inputs\"\"\"\n",
        "    listify = [a,b]\n",
        "    random.shuffle(listify)\n",
        "    return listify[0], listify[1]\n",
        "\n",
        "@tf.function\n",
        "def scale_image(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Convert all images to float32\"\"\"\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def gaussian_blur(image: tf.Tensor, kernel_size:int=23, padding: str='SAME') -> tf.Tensor:\n",
        "    \"\"\"\n",
        "    Randomly apply Gaussian Blur to the input image\n",
        "    \n",
        "    Reference: https://github.com/google-research/simclr/blob/master/data_util.py\n",
        "    \"\"\"\n",
        "\n",
        "    sigma = tf.random.uniform((1,))* 1.9 + 0.1\n",
        "    radius = tf.cast(kernel_size / 2, tf.int32)\n",
        "    kernel_size = radius * 2 + 1\n",
        "    x = tf.cast(tf.range(-radius, radius + 1), tf.float32)\n",
        "    blur_filter = tf.exp(\n",
        "        -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.cast(sigma, tf.float32), 2.0)))\n",
        "    blur_filter /= tf.reduce_sum(blur_filter)\n",
        "\n",
        "    # One vertical and one horizontal filter.\n",
        "    blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "    blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "    num_channels = tf.shape(image)[-1]\n",
        "    blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "    blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "    expand_batch_dim = image.shape.ndims == 3\n",
        "    if expand_batch_dim:\n",
        "      image = tf.expand_dims(image, axis=0)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "    blurred = tf.nn.depthwise_conv2d(\n",
        "        blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "    if expand_batch_dim:\n",
        "      blurred = tf.squeeze(blurred, axis=0)\n",
        "    return blurred\n",
        "\n",
        "@tf.function\n",
        "def color_jitter(image: tf.Tensor, s: float = 0.5) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply Color Jittering to the input image\"\"\"\n",
        "    x = tf.image.random_brightness(image, max_delta=0.8*s)\n",
        "    x = tf.image.random_contrast(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_saturation(x, lower=1-0.8*s, upper=1+0.8*s)\n",
        "    x = tf.image.random_hue(x, max_delta=0.2*s)\n",
        "    x = tf.clip_by_value(x, 0, 1)\n",
        "    return x\n",
        "\n",
        "@tf.function\n",
        "def solarize(image: tf.Tensor, threshold: int = 128) -> tf.Tensor:\n",
        "    \"\"\"Solarize the input image\"\"\"\n",
        "    return tf.where(image < threshold, image, 255 - image)\n",
        "\n",
        "@tf.function\n",
        "def color_drop(image: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Randomly convert the input image to GrayScale\"\"\"\n",
        "    image = tf.image.rgb_to_grayscale(image)\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "    return image\n",
        "\n",
        "@tf.function\n",
        "def random_apply(func: Callable, x: tf.Tensor, p: float) -> tf.Tensor:\n",
        "    \"\"\"Randomly apply the desired func to the input image\"\"\"\n",
        "    return tf.cond(\n",
        "        tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "                tf.cast(p, tf.float32)),\n",
        "        lambda: func(x),\n",
        "        lambda: x)\n",
        "\n",
        "@tf.function\n",
        "def custom_augment_train(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0) -> Tuple[tf.Tensor]:       \n",
        "    \"\"\"Container function to apply all custom augmentations\"\"\"\n",
        "    # Random flips\n",
        "    image = random_apply(tf.image.flip_left_right, image, p=0.5)\n",
        "    # Randomly apply transformation (color distortions) with probability p.\n",
        "    image = random_apply(color_jitter, image, p=0.8)\n",
        "    # Randomly apply grayscale\n",
        "    image = random_apply(color_drop, image, p=0.2)\n",
        "    # Randomly apply gausian blur\n",
        "    image = random_apply(gaussian_blur, image, p=gaussian_p)\n",
        "    # Randomly apply solarization\n",
        "    image = random_apply(solarize, image, p=solarize_p)\n",
        "\n",
        "    return (image, label)\n",
        "\n",
        "@tf.function\n",
        "def custom_augment_eval(image: tf.Tensor, label: tf.Tensor, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
        "    # image resizing\n",
        "    image_shape = 260\n",
        "    image = tf.image.resize(image, (image_shape, image_shape))\n",
        "    # get the crop from the image\n",
        "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
        "    resized_image = tf.image.resize(crop, (crop_size, crop_size))\n",
        "    return resized_image, label\n",
        "\n",
        "@tf.function\n",
        "def train_augmentations(image: tf.Tensor, label: tf.Tensor, gaussian_p: float = 0.1, solarize_p: float = 0.0, crop_size:int = 224) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Resize and Augment Crops\"\"\"\n",
        "    # scale the pixel values\n",
        "    image, label = scale_image(image , label)\n",
        "    # image resizing\n",
        "    image_shape = 260\n",
        "    image = tf.image.resize(image, (image_shape, image_shape))\n",
        "    # get the crop from the image\n",
        "    crop = tf.image.random_crop(image, (crop_size,crop_size,3))\n",
        "    crop_resize = tf.image.resize(crop, (crop_size, crop_size))\n",
        "    # color distortions\n",
        "    distored_image, label = custom_augment_train(crop_resize, label, gaussian_p)\n",
        "    return distored_image, label\n",
        "\n",
        "@tf.function\n",
        "def eval_augmentations(image: tf.Tensor, label: tf.Tensor) -> Tuple[tf.Tensor]:\n",
        "    \"\"\"Randomly Augment Images for Evaluation\"\"\"\n",
        "    # Scale the pixel values\n",
        "    image, label = scale_image(image , label)\n",
        "    # random horizontal flip\n",
        "    image = random_apply(tf.image.random_flip_left_right, image, p=0.5)\n",
        "    # Random resized crops\n",
        "    image, label = custom_augment_eval(image, label)\n",
        "\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "FECY7V4i-qn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💿 The Dataset\n",
        "---\n",
        "\n",
        "For the purposes of this example, we use the TF Flowers dataset."
      ],
      "metadata": {
        "id": "2Ek4byqT-v_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "# Gather Flowers dataset\n",
        "train_ds, validation_ds = tfds.load(\n",
        "    \"tf_flowers\",\n",
        "    split=[\"train[:85%]\", \"train[85%:]\"],\n",
        "    as_supervised=True\n",
        ")"
      ],
      "metadata": {
        "id": "Npn7dxcS-vvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🖖 Data Augmentation Pipeline\n"
      ],
      "metadata": {
        "id": "KY-kEh1z-0R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create a Tuple because we have two loaders corresponding to each view\n",
        "trainloaders = tuple()\n",
        "\n",
        "for i in range(NUM_VIEWS):\n",
        "  trainloader = (\n",
        "      train_ds\n",
        "      .shuffle(1024)\n",
        "      .map(lambda x, y: train_augmentations(x, y, GAUSSIAN_P[i], SOLARIZE_P[i]), num_parallel_calls=AUTOTUNE)\n",
        "  )\n",
        "  trainloader = trainloader.with_options(options)\n",
        "  trainloaders+=(trainloader,)"
      ],
      "metadata": {
        "id": "hkPeC6gT-17p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ⚙️ Dataloader\n"
      ],
      "metadata": {
        "id": "hAH1MKOl-4j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# zip both the dataloaders together\n",
        "trainloader = tf.data.Dataset.zip(trainloaders)\n",
        "\n",
        "# final trainloader to be used for training\n",
        "trainloader = (\n",
        "    trainloader\n",
        "    .batch(TRAIN_BATCH_SIZE * strategy.num_replicas_in_sync)\n",
        "    .map(shuffle_zipped_output, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "zSK1nZvU-5RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ✍️ Model Architecture & Training\n",
        "---"
      ],
      "metadata": {
        "id": "Cad8GVkt_Zfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏠 Building the network\n",
        "\n",
        "![](https://camo.githubusercontent.com/9cffe6a81978d546ca3c54c02e634d432c1be29ace3b2560d3f4a19710aa6654/68747470733a2f2f6769746875622e636f6d2f66616365626f6f6b72657365617263682f7669637265672f626c6f622f6d61696e2f2e6769746875622f7669637265675f61726368695f66756c6c2e6a70673f7261773d74727565)"
      ],
      "metadata": {
        "id": "ODARQQ1W_boI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_encoder():\n",
        "  base_model, base_model_variables = pretrained_resnet(size=50)\n",
        "  backbone = nn.Sequential(base_model().layers[:-1])\n",
        "  backbone_variables = common.slice_variables(base_model_variables, end = -1)\n",
        "\n",
        "  return backbone, backbone_variables"
      ],
      "metadata": {
        "id": "JRaTxkEcHowL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "encoder, encoder_variables = get_encoder()\n",
        "encoder_output = encoder.apply(encoder_variables,\n",
        "                  jnp.ones((32, 224, 224, 3)),  # ImageNet sized inputs.\n",
        "                  mutable=False)\n",
        "assert encoder_output.shape == (32, 2048)\n",
        "del encoder, encoder_variables, encoder_output"
      ],
      "metadata": {
        "id": "c-T1uC-1HXSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Expander(nn.Module):\n",
        "  num_units: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, inputs, train: bool):\n",
        "    projection_1 = nn.Dense(features = self.num_units)(inputs)\n",
        "    projection_1 = nn.BatchNorm(use_running_average=not train)(projection_1)\n",
        "    projection_1 = nn.relu(projection_1)\n",
        "\n",
        "    projection_2 = nn.Dense(features = self.num_units)(projection_1)\n",
        "    projection_2 = nn.BatchNorm(use_running_average=not train)(projection_2)\n",
        "    projection_2 = nn.relu(projection_2)\n",
        "\n",
        "    return nn.Dense(features = self.num_units)(projection_2)\n",
        "\n",
        "expander = Expander(num_units = 8192)"
      ],
      "metadata": {
        "id": "WZzA9kGMJlVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "variables = expander.init(jax.random.PRNGKey(0), jnp.ones((2048, 8192)), train=False)\n",
        "params, batch_stats = variables['params'], variables['batch_stats']\n",
        "expander_output , _ = expander.apply(\n",
        "  {'params': params, 'batch_stats': batch_stats},\n",
        "  jnp.ones((2048, 8192)),\n",
        "  train=True, mutable=['batch_stats']\n",
        ")\n",
        "assert expander_output.shape == (2048, 8192)\n",
        "\n",
        "del expander, variables, params, batch_stats, expander_output"
      ],
      "metadata": {
        "id": "DG364LhZLKzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VICReg(nn.Module):\n",
        "  encoder: nn.Sequential\n",
        "  expander: nn.Module"
      ],
      "metadata": {
        "id": "6KkFVT9GCSnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🎬 Initializing the Module\n"
      ],
      "metadata": {
        "id": "0vDuamTW_i_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 🏋️‍♂️ Train Step\n"
      ],
      "metadata": {
        "id": "Bd89Mi-Q_l1y"
      }
    }
  ]
}
